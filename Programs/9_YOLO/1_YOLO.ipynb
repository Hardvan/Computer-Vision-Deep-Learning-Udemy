{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from model.yolo_model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \"\"\"Resize, redice and expand image.\n",
    "\n",
    "    Args:\n",
    "        img (): original image.\n",
    "    \n",
    "    Returns:\n",
    "        image: ndarray(64, 64, 3): processed image.\n",
    "    \"\"\"\n",
    "    \n",
    "    image = cv2.resize(img, (416, 416),\n",
    "                       interpolation=cv2.INTER_CUBIC)\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image /= 255.\n",
    "    image = np.expand_dims(image, 0)  # Add batch dimension.\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(file_path):\n",
    "    \"\"\"Get classes from file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): path to classes file.\n",
    "    \n",
    "    Returns:\n",
    "        classes (list): list of classes.\n",
    "    \"\"\"\n",
    "    with open(file_path) as f:\n",
    "        classes = f.readlines()\n",
    "    classes = [c.strip() for c in classes]\n",
    "    \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image, boxes, scores, classes, all_classes):\n",
    "    \"\"\"Draw the boxed on the image.\n",
    "\n",
    "    Args:\n",
    "        image: original image.\n",
    "        boxes: boxes of objects.\n",
    "        scores: scores of objects.\n",
    "        classes: classes of objects.\n",
    "        all_classes: list of all classes.\n",
    "    \"\"\"\n",
    "\n",
    "    for box, score, cl in zip(boxes, scores, classes):\n",
    "        x, y, w, h = box\n",
    "        \n",
    "        top = max(0, np.floor(x + 0.5).astype(int))\n",
    "        left = max(0, np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
    "        \n",
    "        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "        mess = '%s: %.3f' % (all_classes[cl], score)\n",
    "        cv2.putText(image, mess, (top, left - 12),\n",
    "                    0, 1e-3 * image.shape[0], (0, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect objects in image.\n",
    "\n",
    "    Args:\n",
    "        image: original image.\n",
    "        yolo: yolo v3 model.\n",
    "        all_classes: list of all classes.\n",
    "    \n",
    "    Returns:\n",
    "        image: image with boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    pimage = process_image(image)\n",
    "    \n",
    "    start = time.time()\n",
    "    boxes, scores, classes = yolo.predict(pimage, image.shape)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Time: {:.2f}s, Detect Objects: {:d}.\".format(end - start, len(boxes)))\n",
    "    \n",
    "    if len(boxes) != 0:\n",
    "        draw(image, boxes, scores, classes, all_classes)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(video, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect video.\n",
    "\n",
    "    # Argument:\n",
    "        video: video file.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    video_path = os.path.join(\"videos\", \"test\", video)\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # Prepare for saving the detected video\n",
    "    sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n",
    "\n",
    "    \n",
    "    vout = cv2.VideoWriter()\n",
    "    vout.open(os.path.join(\"videos\", \"res\", video), fourcc, 20, sz, True)\n",
    "\n",
    "    while True:\n",
    "        res, frame = camera.read()\n",
    "\n",
    "        if not res:\n",
    "            break\n",
    "\n",
    "        image = detect_image(frame, yolo, all_classes)\n",
    "        cv2.imshow(\"detection\", image)\n",
    "\n",
    "        # Save the video frame by frame\n",
    "        vout.write(image)\n",
    "\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "                break\n",
    "\n",
    "    vout.release()\n",
    "    camera.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO(0.6, 0.5)\n",
    "file = 'data/coco_classes.txt'\n",
    "all_classes = get_classes(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimages/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mf\n\u001b[0;32m      3\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(path)\n\u001b[1;32m----> 4\u001b[0m image \u001b[39m=\u001b[39m detect_image(image, yolo, all_classes)\n\u001b[0;32m      5\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39mimages/res/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m f, image)\n",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m, in \u001b[0;36mdetect_image\u001b[1;34m(image, yolo, all_classes)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_image\u001b[39m(image, yolo, all_classes):\n\u001b[0;32m      2\u001b[0m     \u001b[39m\"\"\"Use yolo v3 to detect objects in image.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m        image: image with boxes.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     pimage \u001b[39m=\u001b[39m process_image(image)\n\u001b[0;32m     15\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     16\u001b[0m     boxes, scores, classes \u001b[39m=\u001b[39m yolo\u001b[39m.\u001b[39mpredict(pimage, image\u001b[39m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_image\u001b[39m(img):\n\u001b[0;32m      2\u001b[0m     \u001b[39m\"\"\"Resize, redice and expand image.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m        image: ndarray(64, 64, 3): processed image.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mresize(img, (\u001b[39m416\u001b[39;49m, \u001b[39m416\u001b[39;49m),\n\u001b[0;32m     12\u001b[0m                        interpolation\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mINTER_CUBIC)\n\u001b[0;32m     13\u001b[0m     image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(image, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m     image \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m255.\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "f = 'jingxiang-gao-489454-unsplash.jpg'\n",
    "path = 'images/'+f\n",
    "image = cv2.imread(path)\n",
    "image = detect_image(image, yolo, all_classes)\n",
    "cv2.imwrite('images/res/' + f, image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Lesson Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
